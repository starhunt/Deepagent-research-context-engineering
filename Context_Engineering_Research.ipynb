{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c897bc9",
   "metadata": {},
   "source": [
    "# Context Engineering 연구 노트북\n",
    "\n",
    "DeepAgents 라이브러리에서 사용되는 5가지 Context Engineering 전략을 분석하고 실험합니다.\n",
    "\n",
    "## Context Engineering 5가지 핵심 전략\n",
    "\n",
    "| 전략 | 설명 | DeepAgents 구현 |\n",
    "|------|------|----------------|\n",
    "| **1. Offloading** | 대용량 결과를 파일로 축출 | FilesystemMiddleware |\n",
    "| **2. Reduction** | Compaction + Summarization | SummarizationMiddleware |\n",
    "| **3. Retrieval** | grep/glob 기반 검색 | FilesystemMiddleware |\n",
    "| **4. Isolation** | SubAgent로 컨텍스트 격리 | SubAgentMiddleware |\n",
    "| **5. Caching** | Prompt Caching | AnthropicPromptCachingMiddleware |\n",
    "\n",
    "## 아키텍처 개요\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                     Context Engineering                          │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                  │\n",
    "│   ┌────────────┐    ┌────────────┐    ┌────────────┐            │\n",
    "│   │ Offloading │    │ Reduction  │    │  Caching   │            │\n",
    "│   │ (20k 토큰) │    │ (85% 임계) │    │ (Anthropic)│            │\n",
    "│   └─────┬──────┘    └─────┬──────┘    └─────┬──────┘            │\n",
    "│         │                 │                 │                    │\n",
    "│         ▼                 ▼                 ▼                    │\n",
    "│   ┌─────────────────────────────────────────────────────┐       │\n",
    "│   │              Middleware Stack                       │       │\n",
    "│   └─────────────────────────────────────────────────────┘       │\n",
    "│                          │                                       │\n",
    "│         ┌────────────────┼────────────────┐                     │\n",
    "│         ▼                ▼                ▼                     │\n",
    "│   ┌────────────┐  ┌────────────┐  ┌────────────┐               │\n",
    "│   │ Retrieval  │  │ Isolation  │  │  Backend   │               │\n",
    "│   │(grep/glob) │  │ (SubAgent) │  │ (FileSystem│               │\n",
    "│   └────────────┘  └────────────┘  └────────────┘               │\n",
    "│                                                                  │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategy1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 전략 1: Context Offloading\n",
    "\n",
    "대용량 도구 결과를 파일시스템으로 축출하여 컨텍스트 윈도우 오버플로우를 방지합니다.\n",
    "\n",
    "### 핵심 원리\n",
    "- 도구 결과가 `tool_token_limit_before_evict` (기본 20,000 토큰) 초과 시 자동 축출\n",
    "- `/large_tool_results/{tool_call_id}` 경로에 저장\n",
    "- 처음 10줄 미리보기 제공\n",
    "- 에이전트가 `read_file`로 필요할 때 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offloading_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_research_agent.context_strategies.offloading import (\n",
    "    ContextOffloadingStrategy,\n",
    "    OffloadingConfig,\n",
    ")\n",
    "\n",
    "config = OffloadingConfig(\n",
    "    token_limit_before_evict=20000,\n",
    "    eviction_path_prefix=\"/large_tool_results\",\n",
    "    preview_lines=10,\n",
    ")\n",
    "\n",
    "print(f\"토큰 임계값: {config.token_limit_before_evict:,}\")\n",
    "print(f\"축출 경로: {config.eviction_path_prefix}\")\n",
    "print(f\"미리보기 줄 수: {config.preview_lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offloading_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = ContextOffloadingStrategy(config=config)\n",
    "\n",
    "small_content = \"짧은 텍스트\" * 100\n",
    "large_content = \"대용량 텍스트\" * 30000\n",
    "\n",
    "print(f\"짧은 콘텐츠: {len(small_content)} 자 → 축출 대상: {strategy._should_offload(small_content)}\")\n",
    "print(f\"대용량 콘텐츠: {len(large_content):,} 자 → 축출 대상: {strategy._should_offload(large_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategy2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 전략 2: Context Reduction\n",
    "\n",
    "컨텍스트 윈도우 사용량이 임계값을 초과할 때 자동으로 대화 내용을 압축합니다.\n",
    "\n",
    "### 두 가지 기법\n",
    "\n",
    "| 기법 | 설명 | 비용 |\n",
    "|------|------|------|\n",
    "| **Compaction** | 오래된 도구 호출/결과 제거 | 무료 |\n",
    "| **Summarization** | LLM이 대화 요약 | API 비용 발생 |\n",
    "\n",
    "우선순위: Compaction → Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduction_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_research_agent.context_strategies.reduction import (\n",
    "    ContextReductionStrategy,\n",
    "    ReductionConfig,\n",
    ")\n",
    "\n",
    "config = ReductionConfig(\n",
    "    context_threshold=0.85,\n",
    "    model_context_window=200000,\n",
    "    compaction_age_threshold=10,\n",
    "    min_messages_to_keep=5,\n",
    ")\n",
    "\n",
    "print(f\"임계값: {config.context_threshold * 100}%\")\n",
    "print(f\"컨텍스트 윈도우: {config.model_context_window:,} 토큰\")\n",
    "print(f\"Compaction 대상 나이: {config.compaction_age_threshold} 메시지\")\n",
    "print(f\"최소 유지 메시지: {config.min_messages_to_keep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduction_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "strategy = ContextReductionStrategy(config=config)\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"안녕하세요\" * 1000),\n",
    "    AIMessage(content=\"안녕하세요\" * 1000),\n",
    "] * 20\n",
    "\n",
    "usage_ratio = strategy._get_context_usage_ratio(messages)\n",
    "print(f\"컨텍스트 사용률: {usage_ratio * 100:.1f}%\")\n",
    "print(f\"축소 필요: {strategy._should_reduce(messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategy3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 전략 3: Context Retrieval\n",
    "\n",
    "grep/glob 기반의 단순하고 빠른 검색으로 필요한 정보만 선택적으로 로드합니다.\n",
    "\n",
    "### 벡터 검색을 사용하지 않는 이유\n",
    "\n",
    "| 특성 | 직접 검색 | 벡터 검색 |\n",
    "|------|----------|----------|\n",
    "| 결정성 | ✅ 정확한 매칭 | ❌ 확률적 |\n",
    "| 인프라 | ✅ 불필요 | ❌ 벡터 DB 필요 |\n",
    "| 속도 | ✅ 빠름 | ❌ 인덱싱 오버헤드 |\n",
    "| 디버깅 | ✅ 예측 가능 | ❌ 블랙박스 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retrieval_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_research_agent.context_strategies.retrieval import (\n",
    "    ContextRetrievalStrategy,\n",
    "    RetrievalConfig,\n",
    ")\n",
    "\n",
    "config = RetrievalConfig(\n",
    "    default_read_limit=500,\n",
    "    max_grep_results=100,\n",
    "    max_glob_results=100,\n",
    "    truncate_line_length=2000,\n",
    ")\n",
    "\n",
    "print(f\"기본 읽기 제한: {config.default_read_limit} 줄\")\n",
    "print(f\"grep 최대 결과: {config.max_grep_results}\")\n",
    "print(f\"glob 최대 결과: {config.max_glob_results}\")\n",
    "print(f\"줄 길이 제한: {config.truncate_line_length} 자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategy4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 전략 4: Context Isolation\n",
    "\n",
    "SubAgent를 통해 독립된 컨텍스트 윈도우에서 작업을 수행합니다.\n",
    "\n",
    "### 장점\n",
    "- 메인 에이전트 컨텍스트 오염 방지\n",
    "- 복잡한 작업의 격리 처리\n",
    "- 병렬 처리 가능\n",
    "\n",
    "### SubAgent 유형\n",
    "\n",
    "| 유형 | 구조 | 특징 |\n",
    "|------|------|------|\n",
    "| Simple | `{name, system_prompt, tools}` | 단일 응답 |\n",
    "| Compiled | `{name, runnable}` | 자체 DeepAgent, 다중 턴 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolation_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_research_agent.context_strategies.isolation import (\n",
    "    ContextIsolationStrategy,\n",
    "    IsolationConfig,\n",
    ")\n",
    "\n",
    "config = IsolationConfig(\n",
    "    default_model=\"gpt-4.1\",\n",
    "    include_general_purpose_agent=True,\n",
    "    excluded_state_keys=(\"messages\", \"todos\", \"structured_response\"),\n",
    ")\n",
    "\n",
    "print(f\"기본 모델: {config.default_model}\")\n",
    "print(f\"범용 에이전트 포함: {config.include_general_purpose_agent}\")\n",
    "print(f\"제외 상태 키: {config.excluded_state_keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategy5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 전략 5: Context Caching\n",
    "\n",
    "Anthropic Prompt Caching을 활용하여 시스템 프롬프트와 반복 컨텍스트를 캐싱합니다.\n",
    "\n",
    "### 이점\n",
    "- API 호출 비용 절감\n",
    "- 응답 속도 향상\n",
    "- 동일 세션 내 반복 호출 최적화\n",
    "\n",
    "### 캐싱 조건\n",
    "- 최소 1,024 토큰 이상\n",
    "- `cache_control: {\"type\": \"ephemeral\"}` 마커 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caching_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_research_agent.context_strategies.caching import (\n",
    "    ContextCachingStrategy,\n",
    "    CachingConfig,\n",
    ")\n",
    "\n",
    "config = CachingConfig(\n",
    "    min_cacheable_tokens=1024,\n",
    "    cache_control_type=\"ephemeral\",\n",
    "    enable_for_system_prompt=True,\n",
    "    enable_for_tools=True,\n",
    ")\n",
    "\n",
    "print(f\"최소 캐싱 토큰: {config.min_cacheable_tokens:,}\")\n",
    "print(f\"캐시 컨트롤 타입: {config.cache_control_type}\")\n",
    "print(f\"시스템 프롬프트 캐싱: {config.enable_for_system_prompt}\")\n",
    "print(f\"도구 캐싱: {config.enable_for_tools}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caching_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = ContextCachingStrategy(config=config)\n",
    "\n",
    "short_content = \"짧은 시스템 프롬프트\"\n",
    "long_content = \"긴 시스템 프롬프트 \" * 500\n",
    "\n",
    "print(f\"짧은 콘텐츠: {len(short_content)} 자 → 캐싱 대상: {strategy._should_cache(short_content)}\")\n",
    "print(f\"긴 콘텐츠: {len(long_content):,} 자 → 캐싱 대상: {strategy._should_cache(long_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integration",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 통합 에이전트 실행\n",
    "\n",
    "5가지 전략이 모두 적용된 에이전트를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent_create",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_research_agent import create_context_aware_agent\n",
    "\n",
    "agent = create_context_aware_agent(\n",
    "    model_name=\"gpt-4.1\",\n",
    "    enable_offloading=True,\n",
    "    enable_reduction=True,\n",
    "    enable_caching=True,\n",
    "    offloading_token_limit=20000,\n",
    "    reduction_threshold=0.85,\n",
    ")\n",
    "\n",
    "print(f\"에이전트 타입: {type(agent).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 전략 활성화/비활성화 비교 실험\n",
    "\n",
    "각 전략을 활성화/비활성화했을 때의 차이점을 실험합니다.\n",
    "\n",
    "### 실험 설계\n",
    "\n",
    "| 실험 | Offloading | Reduction | Caching | 목적 |\n",
    "|------|------------|-----------|---------|------|\n",
    "| 1. 기본 | ❌ | ❌ | ❌ | 베이스라인 |\n",
    "| 2. Offloading만 | ✅ | ❌ | ❌ | 대용량 결과 축출 효과 |\n",
    "| 3. Reduction만 | ❌ | ✅ | ❌ | 컨텍스트 압축 효과 |\n",
    "| 4. 모두 활성화 | ✅ | ✅ | ✅ | 전체 효과 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_research_agent.context_strategies.offloading import (\n",
    "    ContextOffloadingStrategy, OffloadingConfig\n",
    ")\n",
    "from context_engineering_research_agent.context_strategies.reduction import (\n",
    "    ContextReductionStrategy, ReductionConfig\n",
    ")\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"전략 비교를 위한 테스트 데이터 생성\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exp1_offloading",
   "metadata": {},
   "source": [
    "### 실험 1: Offloading 전략 효과\n",
    "\n",
    "대용량 도구 결과가 있을 때 Offloading 활성화/비활성화 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exp1_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_result = \"검색 결과: 항목 1, 항목 2, 항목 3\"\n",
    "large_result = \"\\n\".join([f\"검색 결과 {i}: \" + \"상세 내용 \" * 100 for i in range(500)])\n",
    "\n",
    "print(f\"작은 결과 크기: {len(small_result):,} 자\")\n",
    "print(f\"대용량 결과 크기: {len(large_result):,} 자\")\n",
    "print()\n",
    "\n",
    "offloading_disabled = ContextOffloadingStrategy(\n",
    "    config=OffloadingConfig(token_limit_before_evict=999999999)\n",
    ")\n",
    "offloading_enabled = ContextOffloadingStrategy(\n",
    "    config=OffloadingConfig(token_limit_before_evict=20000)\n",
    ")\n",
    "\n",
    "print(\"[Offloading 비활성화 시]\")\n",
    "print(f\"  작은 결과 축출: {offloading_disabled._should_offload(small_result)}\")\n",
    "print(f\"  대용량 결과 축출: {offloading_disabled._should_offload(large_result)}\")\n",
    "print(f\"  → 대용량 결과가 컨텍스트에 그대로 포함됨\")\n",
    "print()\n",
    "\n",
    "print(\"[Offloading 활성화 시]\")\n",
    "print(f\"  작은 결과 축출: {offloading_enabled._should_offload(small_result)}\")\n",
    "print(f\"  대용량 결과 축출: {offloading_enabled._should_offload(large_result)}\")\n",
    "print(f\"  → 대용량 결과는 파일로 저장, 미리보기만 컨텍스트에 포함\")\n",
    "print()\n",
    "\n",
    "preview = offloading_enabled._create_preview(large_result)\n",
    "print(f\"미리보기 크기: {len(preview):,} 자 (원본의 {len(preview)/len(large_result)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exp2_reduction",
   "metadata": {},
   "source": [
    "### 실험 2: Reduction 전략 효과\n",
    "\n",
    "긴 대화에서 Compaction 적용 전/후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exp2_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_with_tools = []\n",
    "for i in range(30):\n",
    "    messages_with_tools.append(HumanMessage(content=f\"질문 {i}: \" + \"내용 \" * 50))\n",
    "    ai_msg = AIMessage(\n",
    "        content=f\"답변 {i}: \" + \"응답 \" * 50,\n",
    "        tool_calls=[{'id': f'call_{i}', 'name': 'search', 'args': {'q': 'test'}}] if i < 25 else []\n",
    "    )\n",
    "    messages_with_tools.append(ai_msg)\n",
    "    if i < 25:\n",
    "        messages_with_tools.append(ToolMessage(content=f\"도구 결과 {i}: \" + \"결과 \" * 30, tool_call_id=f'call_{i}'))\n",
    "\n",
    "reduction = ContextReductionStrategy(\n",
    "    config=ReductionConfig(compaction_age_threshold=10)\n",
    ")\n",
    "\n",
    "original_tokens = reduction._estimate_tokens(messages_with_tools)\n",
    "print(f\"[Reduction 비활성화 시]\")\n",
    "print(f\"  메시지 수: {len(messages_with_tools)}\")\n",
    "print(f\"  추정 토큰: {original_tokens:,}\")\n",
    "print(f\"  → 모든 도구 호출/결과가 컨텍스트에 유지됨\")\n",
    "print()\n",
    "\n",
    "compacted, result = reduction.apply_compaction(messages_with_tools)\n",
    "compacted_tokens = reduction._estimate_tokens(compacted)\n",
    "\n",
    "print(f\"[Reduction 활성화 시 - Compaction]\")\n",
    "print(f\"  메시지 수: {len(messages_with_tools)} → {len(compacted)}\")\n",
    "print(f\"  추정 토큰: {original_tokens:,} → {compacted_tokens:,}\")\n",
    "print(f\"  절약된 토큰: {result.estimated_tokens_saved:,} ({result.estimated_tokens_saved/original_tokens*100:.1f}%)\")\n",
    "print(f\"  → 오래된 도구 호출/결과가 제거되어 컨텍스트 효율화\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exp3_combined",
   "metadata": {},
   "source": [
    "### 실험 3: 전략 조합 효과 시뮬레이션\n",
    "\n",
    "모든 전략을 함께 적용했을 때의 시너지 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exp3_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"시나리오: 복잡한 연구 작업 수행\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "scenario = {\n",
    "    \"대화 턴 수\": 50,\n",
    "    \"도구 호출 수\": 40,\n",
    "    \"대용량 결과 수\": 5,\n",
    "    \"평균 결과 크기\": \"100k 자\",\n",
    "}\n",
    "\n",
    "print(\"[시나리오 설정]\")\n",
    "for k, v in scenario.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print()\n",
    "\n",
    "baseline_context = 50 * 500 + 40 * 300 + 5 * 100000\n",
    "print(\"[모든 전략 비활성화 시]\")\n",
    "print(f\"  예상 컨텍스트 크기: {baseline_context:,} 자 (~{baseline_context//4:,} 토큰)\")\n",
    "print(f\"  문제: 컨텍스트 윈도우 초과 가능성 높음\")\n",
    "print()\n",
    "\n",
    "with_offloading = 50 * 500 + 40 * 300 + 5 * 1000\n",
    "print(\"[Offloading만 활성화 시]\")\n",
    "print(f\"  예상 컨텍스트 크기: {with_offloading:,} 자 (~{with_offloading//4:,} 토큰)\")\n",
    "print(f\"  절약: {(baseline_context - with_offloading):,} 자 ({(baseline_context - with_offloading)/baseline_context*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "with_reduction = with_offloading * 0.6\n",
    "print(\"[Offloading + Reduction 활성화 시]\")\n",
    "print(f\"  예상 컨텍스트 크기: {int(with_reduction):,} 자 (~{int(with_reduction)//4:,} 토큰)\")\n",
    "print(f\"  총 절약: {int(baseline_context - with_reduction):,} 자 ({(baseline_context - with_reduction)/baseline_context*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "print(\"[+ Caching 활성화 시 추가 효과]\")\n",
    "print(f\"  시스템 프롬프트 캐싱으로 반복 호출 비용 90% 절감\")\n",
    "print(f\"  응답 속도 향상\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exp4_live",
   "metadata": {},
   "source": [
    "### 실험 4: 실제 에이전트 실행 비교\n",
    "\n",
    "실제 에이전트를 다른 설정으로 생성하여 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exp4_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_research_agent import create_context_aware_agent\n",
    "\n",
    "print(\"에이전트 생성 비교\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "configs = [\n",
    "    {\"name\": \"기본 (모두 비활성화)\", \"offloading\": False, \"reduction\": False, \"caching\": False},\n",
    "    {\"name\": \"Offloading만\", \"offloading\": True, \"reduction\": False, \"caching\": False},\n",
    "    {\"name\": \"Reduction만\", \"offloading\": False, \"reduction\": True, \"caching\": False},\n",
    "    {\"name\": \"모두 활성화\", \"offloading\": True, \"reduction\": True, \"caching\": True},\n",
    "]\n",
    "\n",
    "for cfg in configs:\n",
    "    agent = create_context_aware_agent(\n",
    "        model_name=\"gpt-4.1\",\n",
    "        enable_offloading=cfg[\"offloading\"],\n",
    "        enable_reduction=cfg[\"reduction\"],\n",
    "        enable_caching=cfg[\"caching\"],\n",
    "    )\n",
    "    print(f\"\\n[{cfg['name']}]\")\n",
    "    print(f\"  Offloading: {'✅' if cfg['offloading'] else '❌'}\")\n",
    "    print(f\"  Reduction:  {'✅' if cfg['reduction'] else '❌'}\")\n",
    "    print(f\"  Caching:    {'✅' if cfg['caching'] else '❌'}\")\n",
    "    print(f\"  에이전트 타입: {type(agent).__name__}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"모든 에이전트가 성공적으로 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exp5_recommendation",
   "metadata": {},
   "source": [
    "### 권장 설정\n",
    "\n",
    "| 사용 사례 | Offloading | Reduction | Caching | 이유 |\n",
    "|----------|------------|-----------|---------|------|\n",
    "| **짧은 대화** | ❌ | ❌ | ✅ | 오버헤드 최소화 |\n",
    "| **일반 작업** | ✅ | ❌ | ✅ | 대용량 결과 대비 |\n",
    "| **장시간 연구** | ✅ | ✅ | ✅ | 모든 최적화 활용 |\n",
    "| **디버깅** | ❌ | ❌ | ❌ | 전체 컨텍스트 확인 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 요약\n",
    "\n",
    "### Context Engineering 5가지 전략 요약\n",
    "\n",
    "| 전략 | 트리거 조건 | 효과 |\n",
    "|------|------------|------|\n",
    "| **Offloading** | 20k 토큰 초과 | 파일로 축출 |\n",
    "| **Reduction** | 85% 사용량 초과 | Compaction/Summarization |\n",
    "| **Retrieval** | 파일 접근 필요 | grep/glob 검색 |\n",
    "| **Isolation** | 복잡한 작업 | SubAgent 위임 |\n",
    "| **Caching** | 1k+ 토큰 시스템 프롬프트 | Prompt Caching |\n",
    "\n",
    "### 핵심 인사이트\n",
    "\n",
    "1. **파일시스템 = 외부 메모리**: 컨텍스트 윈도우는 제한되어 있지만, 파일시스템은 무한\n",
    "2. **점진적 공개**: 모든 정보를 한 번에 로드하지 않고 필요할 때만 로드\n",
    "3. **격리된 실행**: SubAgent로 컨텍스트 오염 방지\n",
    "4. **자동화된 관리**: 에이전트가 직접 컨텍스트를 관리하도록 미들웨어 설계"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
